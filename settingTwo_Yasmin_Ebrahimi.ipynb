{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task completed individually by Yasmin Ebrahimi -  69.95% accuracy achieved with 150 features"
      ],
      "metadata": {
        "id": "fLaxEvDZAilB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal\n",
        "- Build a machine learning pipeline with the minimum number of features  \n",
        "- Achieve over 62.5% accuracy on the test dataset  \n",
        "\n",
        "## Result\n",
        "- Test accuracy: **69.95%**  \n",
        "- Threshold message: “Accuracy target (>=66%) achieved with 150 PCA components!”  \n",
        "- Features used: 150 principal components  \n",
        "- Model: Soft-voting ensemble of Logistic Regression, Random Forest, SVM\n"
      ],
      "metadata": {
        "id": "CcQF514BAgZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8A5VNVf75Fo2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV,train_test_split\n",
        "\n",
        "os.environ[\"OBJC_DISABLE_INITIALIZE_FORK_SAFETY\"] = \"YES\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "vectorizer = TfidfVectorizer(max_features=7000, stop_words='english')\n",
        "X = vectorizer.fit_transform(newsgroups.data)  # Features (18846 samples, 2000 features each)\n",
        "y = newsgroups.target  # Labels (digits 0 to19)"
      ],
      "metadata": {
        "id": "QFBcyVDE5ZBK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sparse to dense for PCA\n",
        "X_dense = X.toarray()"
      ],
      "metadata": {
        "id": "eBnlWWBV5aLB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and test sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "FDaaMRiL5hGY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of X_train\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K--_64Vb5ifA",
        "outputId": "5ddac38c-2886-4d51-f067-33dfe110bde4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (15076, 7000)\n",
            "y_train shape: (15076,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the proportion of non-zero elements (sparseness)\n",
        "nonzero_ratio = np.count_nonzero(X_train) / (X_train.shape[0] * X_train.shape[1])\n",
        "print(f\"Non-zero Ratio: {nonzero_ratio:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLJ4gb6i5j5I",
        "outputId": "c88aca1c-0b20-45f4-9f89-1a0d3873fb79"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-zero Ratio: 0.0068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the eigenvalue distribution\n",
        "# plt.figure(figsize=(8,4))\n",
        "# sns.histplot(X_train.flatten(), bins=50, kde=True)\n",
        "# plt.title(\"Distribution of feature values (TF-IDF)\")\n",
        "# plt.xlabel(\"Feature value\")\n",
        "# plt.ylabel(\"Count\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "2tW_udA55lTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View category distribution\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3LP_B4P6kYh",
        "outputId": "01e2eb31-c8a1-40a8-8cc5-e4f25524057d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0: 639 samples\n",
            "Label 1: 778 samples\n",
            "Label 2: 788 samples\n",
            "Label 3: 786 samples\n",
            "Label 4: 770 samples\n",
            "Label 5: 790 samples\n",
            "Label 6: 780 samples\n",
            "Label 7: 792 samples\n",
            "Label 8: 797 samples\n",
            "Label 9: 795 samples\n",
            "Label 10: 799 samples\n",
            "Label 11: 793 samples\n",
            "Label 12: 787 samples\n",
            "Label 13: 792 samples\n",
            "Label 14: 790 samples\n",
            "Label 15: 798 samples\n",
            "Label 16: 728 samples\n",
            "Label 17: 752 samples\n",
            "Label 18: 620 samples\n",
            "Label 19: 502 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# PCA: Top 150 features\n",
        "pca = PCA(n_components=150, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)"
      ],
      "metadata": {
        "id": "OrrVeMps6mDY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized classifiers\n",
        "log_reg = LogisticRegression(C=1.5, solver='saga', class_weight='balanced', max_iter=3000, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=30, min_samples_split=5, random_state=42)\n",
        "\n",
        "svm = SVC(C=2, gamma=0.005, kernel='rbf', probability=True, random_state=42)\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=250, max_depth=5, learning_rate=0.05, subsample=0.9, colsample_bytree=0.8, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Weighted Voting Classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_reg), ('rf', rf), ('svm', svm), ('xgb', xgb)],\n",
        "    voting='soft',\n",
        "    weights=[1, 2, 3, 3]  # Prioritize stronger models\n",
        ")\n",
        "\n",
        "# Train\n",
        "voting_clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict & evaluate\n",
        "y_pred = voting_clf.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "if accuracy >= 0.68:\n",
        "    print(\"Accuracy target (>=68%) achieved with 150 PCA components!\")\n",
        "else:\n",
        "    print(\"Accuracy <66%. Consider further tuning.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuqvrmiA6qv6",
        "outputId": "505c7b55-69a7-47e1-e6d1-d57b10666491"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 69.95%\n",
            "Accuracy target (>=68%) achieved with 150 PCA components!\n"
          ]
        }
      ]
    }
  ]
}