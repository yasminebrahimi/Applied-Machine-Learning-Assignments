{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2e12f90",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:34:56.391439Z",
          "iopub.status.busy": "2025-05-16T07:34:56.391154Z",
          "iopub.status.idle": "2025-05-16T07:35:05.907438Z",
          "shell.execute_reply": "2025-05-16T07:35:05.906730Z"
        },
        "papermill": {
          "duration": 9.520322,
          "end_time": "2025-05-16T07:35:05.908745",
          "exception": false,
          "start_time": "2025-05-16T07:34:56.388423",
          "status": "completed"
        },
        "tags": [],
        "id": "e2e12f90",
        "outputId": "5c432f4a-f1ca-47cd-b9eb-5e4bdea3c19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# In[1]: Imports & Device\n",
        "import os\n",
        "import tempfile\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "# use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cc130d8",
      "metadata": {
        "id": "7cc130d8"
      },
      "source": [
        "# **Data transforms & DataLoaders for GTSRB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf853fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:35:05.914511Z",
          "iopub.status.busy": "2025-05-16T07:35:05.913816Z",
          "iopub.status.idle": "2025-05-16T07:35:42.028892Z",
          "shell.execute_reply": "2025-05-16T07:35:42.028040Z"
        },
        "papermill": {
          "duration": 36.118997,
          "end_time": "2025-05-16T07:35:42.030056",
          "exception": false,
          "start_time": "2025-05-16T07:35:05.911059",
          "status": "completed"
        },
        "tags": [],
        "id": "2bf853fc",
        "outputId": "91d3182a-6c50-42a1-fa02-ab3f352eaf81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 187M/187M [00:13<00:00, 14.3MB/s]\n",
            "100%|██████████| 89.0M/89.0M [00:06<00:00, 13.2MB/s]\n",
            "100%|██████████| 99.6k/99.6k [00:00<00:00, 195kB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 26640, Test samples: 12630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# In[2]: Data transforms & DataLoaders for GTSRB\n",
        "# GTSRB images are RGB; we'll resize to 224×224 and use ImageNet normalization\n",
        "transform = transforms.Compose([\n",
        "    # force every image to exactly 224×224\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "\n",
        "# download/train/test splits\n",
        "train_dataset = datasets.GTSRB(\n",
        "    root=\"./data\", split=\"train\", transform=transform, download=True\n",
        ")\n",
        "test_dataset  = datasets.GTSRB(\n",
        "    root=\"./data\", split=\"test\",  transform=transform, download=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True\n",
        ")\n",
        "test_loader  = DataLoader(\n",
        "    test_dataset,  batch_size=64, shuffle=False, num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c8fa2f",
      "metadata": {
        "id": "53c8fa2f"
      },
      "source": [
        "# ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c406776",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:35:42.042144Z",
          "iopub.status.busy": "2025-05-16T07:35:42.041917Z",
          "iopub.status.idle": "2025-05-16T07:35:42.766515Z",
          "shell.execute_reply": "2025-05-16T07:35:42.765800Z"
        },
        "papermill": {
          "duration": 0.732218,
          "end_time": "2025-05-16T07:35:42.768001",
          "exception": false,
          "start_time": "2025-05-16T07:35:42.035783",
          "status": "completed"
        },
        "tags": [],
        "id": "8c406776",
        "outputId": "af1f4a0b-419a-49c8-89b1-697b98606b8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 182MB/s]\n"
          ]
        }
      ],
      "source": [
        "# In[3]: Build & adapt pre-trained ResNet-18\n",
        "num_classes = 43  # GTSRB has 43 traffic-sign classes\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# replace final layer\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5306d0a9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:35:42.780954Z",
          "iopub.status.busy": "2025-05-16T07:35:42.780735Z",
          "iopub.status.idle": "2025-05-16T07:35:42.785113Z",
          "shell.execute_reply": "2025-05-16T07:35:42.784488Z"
        },
        "papermill": {
          "duration": 0.012047,
          "end_time": "2025-05-16T07:35:42.786167",
          "exception": false,
          "start_time": "2025-05-16T07:35:42.774120",
          "status": "completed"
        },
        "tags": [],
        "id": "5306d0a9"
      },
      "outputs": [],
      "source": [
        "# In[4]: Accuracy helper\n",
        "@torch.no_grad()\n",
        "def evaluate(net, loader, device):\n",
        "    net.eval()epoc\n",
        "    correct = total = 0\n",
        "    for X, y in loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = net(X).argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total   += y.size(0)\n",
        "    return 100 * correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb603c34",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:35:42.798782Z",
          "iopub.status.busy": "2025-05-16T07:35:42.798269Z",
          "iopub.status.idle": "2025-05-16T07:36:00.969055Z",
          "shell.execute_reply": "2025-05-16T07:36:00.968179Z"
        },
        "papermill": {
          "duration": 18.178342,
          "end_time": "2025-05-16T07:36:00.970181",
          "exception": false,
          "start_time": "2025-05-16T07:35:42.791839",
          "status": "completed"
        },
        "tags": [],
        "id": "eb603c34",
        "outputId": "deb0c7cb-6cd1-4322-eeae-93b9b07a5415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1) Test accuracy before fine-tuning:  3.26%\n"
          ]
        }
      ],
      "source": [
        "# In[5]: Baseline accuracy (before any fine-tuning)\n",
        "baseline_acc = evaluate(model, test_loader, device)\n",
        "print(f\"1) Test accuracy before fine-tuning: {baseline_acc:5.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16b02508",
      "metadata": {
        "id": "16b02508"
      },
      "source": [
        "# Fine tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0c152b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:36:00.982865Z",
          "iopub.status.busy": "2025-05-16T07:36:00.982639Z",
          "iopub.status.idle": "2025-05-16T07:37:01.250192Z",
          "shell.execute_reply": "2025-05-16T07:37:01.249155Z"
        },
        "papermill": {
          "duration": 60.275254,
          "end_time": "2025-05-16T07:37:01.251503",
          "exception": false,
          "start_time": "2025-05-16T07:36:00.976249",
          "status": "completed"
        },
        "tags": [],
        "id": "0f0c152b",
        "outputId": "db5342f0-abe3-47f1-fd67-16c62c91db88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss (1 epoch): 0.2551\n",
            "2) Test accuracy after fine-tuning (pre-quant): 97.98%\n"
          ]
        }
      ],
      "source": [
        "# In[6]: Fine-tune for 1 epoch\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "model.train()\n",
        "running_loss = 0.0\n",
        "for X, y in train_loader:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(model(X), y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "print(f\"Training loss (1 epoch): {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "finetuned_acc = evaluate(model, test_loader, device)\n",
        "print(f\"2) Test accuracy after fine-tuning (pre-quant): {finetuned_acc:5.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85beca0e",
      "metadata": {
        "id": "85beca0e"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6bb6b7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:37:01.264789Z",
          "iopub.status.busy": "2025-05-16T07:37:01.264515Z",
          "iopub.status.idle": "2025-05-16T07:37:01.341039Z",
          "shell.execute_reply": "2025-05-16T07:37:01.340308Z"
        },
        "papermill": {
          "duration": 0.084499,
          "end_time": "2025-05-16T07:37:01.342205",
          "exception": false,
          "start_time": "2025-05-16T07:37:01.257706",
          "status": "completed"
        },
        "tags": [],
        "id": "4f6bb6b7",
        "outputId": "df8fc8a0-d845-4d4d-d3c8-7b2a9374f26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved fine-tuned model to /kaggle/working/resnet18_gtsrb_finetuned.pth\n"
          ]
        }
      ],
      "source": [
        "# In[7]: Save fine-tuned model\n",
        "save_dir = \"/kaggle/working\"\n",
        "prequant_path = os.path.join(save_dir, \"resnet18_gtsrb_finetuned.pth\")\n",
        "torch.save(model.state_dict(), prequant_path)\n",
        "print(f\"Saved fine-tuned model to {prequant_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470b95c9",
      "metadata": {
        "id": "470b95c9"
      },
      "source": [
        "# Model size before quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea41bf5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:37:01.355316Z",
          "iopub.status.busy": "2025-05-16T07:37:01.355120Z",
          "iopub.status.idle": "2025-05-16T07:37:01.359091Z",
          "shell.execute_reply": "2025-05-16T07:37:01.358503Z"
        },
        "papermill": {
          "duration": 0.011535,
          "end_time": "2025-05-16T07:37:01.360098",
          "exception": false,
          "start_time": "2025-05-16T07:37:01.348563",
          "status": "completed"
        },
        "tags": [],
        "id": "cea41bf5",
        "outputId": "fa99695d-f095-4a9b-b395-f5efd5331a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3) Model size before quantization: 44.88 MB\n"
          ]
        }
      ],
      "source": [
        "# In[8]: Model size before quantization\n",
        "def model_size_mb(path):\n",
        "    return os.path.getsize(path) / 1e6\n",
        "\n",
        "size_fp32 = model_size_mb(prequant_path)\n",
        "print(f\"3) Model size before quantization: {size_fp32:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11441227",
      "metadata": {
        "id": "11441227"
      },
      "source": [
        "# Dynamic quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e32e2b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:37:01.373008Z",
          "iopub.status.busy": "2025-05-16T07:37:01.372822Z",
          "iopub.status.idle": "2025-05-16T07:37:01.513809Z",
          "shell.execute_reply": "2025-05-16T07:37:01.513179Z"
        },
        "papermill": {
          "duration": 0.148556,
          "end_time": "2025-05-16T07:37:01.514969",
          "exception": false,
          "start_time": "2025-05-16T07:37:01.366413",
          "status": "completed"
        },
        "tags": [],
        "id": "35e32e2b",
        "outputId": "65bb3a6d-dcf7-4769-b86c-b722974ef1fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): DynamicQuantizedLinear(in_features=512, out_features=43, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In[9]: Dynamic quantization (INT8)\n",
        "# we quantize only the Linear layers\n",
        "model_cpu = model.to(\"cpu\")\n",
        "quantized_model = quantize_dynamic(\n",
        "    model_cpu, {nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "quantized_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ad184b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:37:01.528091Z",
          "iopub.status.busy": "2025-05-16T07:37:01.527877Z",
          "iopub.status.idle": "2025-05-16T07:37:01.593055Z",
          "shell.execute_reply": "2025-05-16T07:37:01.592228Z"
        },
        "papermill": {
          "duration": 0.07311,
          "end_time": "2025-05-16T07:37:01.594266",
          "exception": false,
          "start_time": "2025-05-16T07:37:01.521156",
          "status": "completed"
        },
        "tags": [],
        "id": "62ad184b",
        "outputId": "dee8f6ca-d780-4cf9-f427-a65b0d974129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved quantized model to /kaggle/working/resnet18_gtsrb_quantized.pth\n"
          ]
        }
      ],
      "source": [
        "# In[10]: Save quantized model\n",
        "quant_path = os.path.join(save_dir, \"resnet18_gtsrb_quantized.pth\")\n",
        "torch.save(quantized_model.state_dict(), quant_path)\n",
        "print(f\"Saved quantized model to {quant_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a9b6a8",
      "metadata": {
        "id": "29a9b6a8"
      },
      "source": [
        "# Evaluate quantized accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4aa575",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:37:01.608041Z",
          "iopub.status.busy": "2025-05-16T07:37:01.607814Z",
          "iopub.status.idle": "2025-05-16T07:44:18.571234Z",
          "shell.execute_reply": "2025-05-16T07:44:18.570180Z"
        },
        "papermill": {
          "duration": 436.977977,
          "end_time": "2025-05-16T07:44:18.578793",
          "exception": false,
          "start_time": "2025-05-16T07:37:01.600816",
          "status": "completed"
        },
        "tags": [],
        "id": "9b4aa575",
        "outputId": "8c937a32-616a-45e1-af0e-1c97d3db12a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4) Test accuracy after quantization: 97.97%\n",
            "5) Accuracy drop:  0.01 percentage points\n"
          ]
        }
      ],
      "source": [
        "# In[11]: Evaluate quantized accuracy\n",
        "int8_acc = evaluate(quantized_model, test_loader, \"cpu\")\n",
        "print(f\"4) Test accuracy after quantization: {int8_acc:5.2f}%\")\n",
        "print(f\"5) Accuracy drop: {finetuned_acc - int8_acc:5.2f} percentage points\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff1de20",
      "metadata": {
        "id": "7ff1de20"
      },
      "source": [
        "# Model size after quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e63f32f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:44:18.593012Z",
          "iopub.status.busy": "2025-05-16T07:44:18.592268Z",
          "iopub.status.idle": "2025-05-16T07:44:18.597633Z",
          "shell.execute_reply": "2025-05-16T07:44:18.596941Z"
        },
        "papermill": {
          "duration": 0.013813,
          "end_time": "2025-05-16T07:44:18.598932",
          "exception": false,
          "start_time": "2025-05-16T07:44:18.585119",
          "status": "completed"
        },
        "tags": [],
        "id": "e63f32f1",
        "outputId": "fcf92472-b015-4769-dd9c-2060c30476e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6) Model size after INT8 quantization: 44.81 MB\n",
            "7) Memory saving:  0.1%\n"
          ]
        }
      ],
      "source": [
        "# In[12]: Model size after quantization\n",
        "size_int8 = model_size_mb(quant_path)\n",
        "print(f\"6) Model size after INT8 quantization: {size_int8:.2f} MB\")\n",
        "print(f\"7) Memory saving: {(1 - size_int8/size_fp32)*100:4.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6796d494",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-16T07:44:18.622177Z",
          "iopub.status.busy": "2025-05-16T07:44:18.621498Z",
          "iopub.status.idle": "2025-05-16T07:45:05.258565Z",
          "shell.execute_reply": "2025-05-16T07:45:05.257626Z"
        },
        "papermill": {
          "duration": 46.65553,
          "end_time": "2025-05-16T07:45:05.265707",
          "exception": false,
          "start_time": "2025-05-16T07:44:18.610177",
          "status": "completed"
        },
        "tags": [],
        "id": "6796d494",
        "outputId": "5747f28a-e554-4b1a-d335-99dc4649e34e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8) Avg inference latency (FP32): 35.31 ms/image\n",
            "   Avg inference latency (INT8): 36.12 ms/image\n"
          ]
        }
      ],
      "source": [
        "# In[13]: Inference latency benchmarking\n",
        "def measure_latency(net, loader, device, num_batches=10):\n",
        "    net.eval().to(device)\n",
        "    total_time = 0.0\n",
        "    total_images = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, _) in enumerate(loader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "            X = X.to(device)\n",
        "            start = time.perf_counter()\n",
        "            _ = net(X)\n",
        "            end   = time.perf_counter()\n",
        "            total_time  += (end - start)\n",
        "            total_images += X.size(0)\n",
        "    return (total_time / total_images) * 1000  # ms per image\n",
        "\n",
        "# measure on CPU\n",
        "fp32_latency = measure_latency(model_cpu, test_loader, \"cpu\")\n",
        "int8_latency= measure_latency(quantized_model, test_loader, \"cpu\")\n",
        "\n",
        "print(f\"8) Avg inference latency (FP32): {fp32_latency:5.2f} ms/image\")\n",
        "print(f\"   Avg inference latency (INT8): {int8_latency:5.2f} ms/image\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b07eb33",
      "metadata": {
        "id": "5b07eb33"
      },
      "source": [
        "## Observation/Key Take Away\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f76e6436",
      "metadata": {
        "id": "f76e6436"
      },
      "source": [
        "1) Test accuracy before fine-tuning:  3.26%\n",
        "\n",
        "2) Test accuracy after fine-tuning (pre-quant): 97.98%\n",
        "\n",
        "3) Model size before quantization: 44.88 MB\n",
        "\n",
        "4) Test accuracy after quantization: 97.97%\n",
        "\n",
        "\n",
        "5) Accuracy drop:  0.01 percentage points\n",
        "\n",
        "6) Model size after INT8 quantization: 44.81 MB\n",
        "\n",
        "7) Memory saving:  0.1%\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 617.550089,
      "end_time": "2025-05-16T07:45:08.363542",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-05-16T07:34:50.813453",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}